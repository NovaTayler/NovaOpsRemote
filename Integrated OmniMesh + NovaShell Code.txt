

#!/usr/bin/env python3
"""
OmniMesh + NovaShell Backend - Integrated Distributed AI and E-Commerce Platform
"""
import os
import json
import time
import hashlib
import secrets
import asyncio
import logging
import structlog
import aiohttp
import asyncpg
import redis.asyncio as redis
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from contextlib import asynccontextmanager
import uuid
import pickle
import socket
import random
import string
import base64
import imaplib
import email
import re
import shutil
from pathlib import Path
import numpy as np
from fastapi import FastAPI, HTTPException, Depends, WebSocket, BackgroundTasks, Request, File, UploadFile
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field, validator
import uvicorn
from jose import jwt, JWTError
from passlib.context import CryptContext
import torch
import torch.nn as nn
import torch.optim as optim
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer
import psutil
from celery import Celery
from web3 import Web3, HTTPProvider
from merkletools import MerkleTools
from pqcrypto.kem.kyber512 import generate_keypair as kyber_generate_keypair, encrypt as kyber_encrypt, decrypt as kyber_decrypt
from tenacity import retry, stop_after_attempt
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from fake_useragent import UserAgent
from textblob import TextBlob
from cryptography.fernet import Fernet

# Configuration
@dataclass
class Config:
    NODE_ID: str = f"om-{secrets.token_hex(16)}"
    SECRET_KEY: str = os.getenv("SECRET_KEY", secrets.token_urlsafe(64))
    JWT_SECRET: str = os.getenv("JWT_SECRET", secrets.token_urlsafe(64))
    ADMIN_PASSWORD: str = os.getenv("ADMIN_PASSWORD", "secure_omnimesh_pass_2025")
    HOST: str = "0.0.0.0"
    PORT: int = 8080
    MESH_PORT: int = 8081
    DB_URL: str = os.getenv("DB_URL", "postgresql://omnimesh:password@localhost:5432/omnimesh")
    REDIS_URL: str = os.getenv("REDIS_URL", "redis://localhost:6379/0")
    MODEL_PATH: str = "./models"
    TORCH_DEVICE: str = "cuda" if torch.cuda.is_available() else "cpu"
    ETH_RPC: str = "https://sepolia.infura.io/v3/3a9e07a6f33f4b80bf61c4e56f2c7eb6"
    CONTRACT_ADDRESS: str = "0x5B38Da6a701c568545dCfcB03FcB875f56beddC4"
    CELERY_BROKER_URL: str = os.getenv("CELERY_BROKER_URL", "redis://localhost:6379/1")
    CELERY_RESULT_BACKEND: str = os.getenv("CELERY_RESULT_BACKEND", "redis://localhost:6379/2")
    LOG_LEVEL: str = "INFO"
    FRONTEND_URL: str = os.getenv("FRONTEND_URL", "http://localhost:3000")
    SUPPLIERS: List[str] = os.getenv("SUPPLIERS", "CJ Dropshipping,AliExpress").split(",")
    PLATFORMS: List[str] = ["eBay", "Amazon", "Walmart", "Etsy", "Shopify"]
    MAX_LISTINGS: int = int(os.getenv("MAX_LISTINGS", 500))
    EMAIL_PROVIDER: str = os.getenv("EMAIL_PROVIDER", "imap.gmail.com")
    EMAIL_USER: str = os.getenv("EMAIL_USER")
    EMAIL_PASS: str = os.getenv("EMAIL_PASS")

config = Config()

# Logging (Adopt NovaShell’s structlog)
structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ],
    logger_factory=structlog.stdlib.LoggerFactory(),
)
logger = structlog.get_logger()

# Vault Manager (Adopt NovaShell’s whispersec.py)
class VaultManager:
    def __init__(self, vault_file="secrets.vault", key_file="vault.key"):
        self.vault_file = vault_file
        self.key_file = key_file
        self.vault_data = {}
        self.cipher = self._init_cipher()
        self.load_vault()

    def _init_cipher(self):
        if not os.path.exists(self.key_file):
            key = Fernet.generate_key()
            with open(self.key_file, "wb") as f:
                f.write(key)
        else:
            with open(self.key_file, "rb") as f:
                key = f.read()
        return Fernet(key)

    def load_vault(self):
        if not os.path.exists(self.vault_file):
            self.vault_data = {}
            self.save_vault()
        else:
            with open(self.vault_file, "rb") as f:
                encrypted = f.read()
            self.vault_data = json.loads(self.cipher.decrypt(encrypted).decode())

    def save_vault(self):
        encrypted = self.cipher.encrypt(json.dumps(self.vault_data).encode())
        with open(self.vault_file, "wb") as f:
            f.write(encrypted)

    def store_secret(self, key: str, value: str):
        self.vault_data[key] = self.cipher.encrypt(value.encode()).decode()
        self.save_vault()

    def get_secret(self, key: str) -> Optional[str]:
        encrypted = self.vault_data.get(key)
        return self.cipher.decrypt(encrypted.encode()).decode() if encrypted else None

    async def register_user(self, email: str, password: str, role: str = "user"):
        try:
            hashed_password = hashlib.sha256(password.encode()).hexdigest()
            self.store_secret(f"auth_{email}", json.dumps({"password": hashed_password, "role": role}))
            logger.info("User registered", email=email)
            return True
        except Exception as e:
            logger.error("User registration failed", email=email, error=str(e))
            raise

    async def validate_user(self, email: str, password: str) -> Optional[str]:
        try:
            user_data = self.get_secret(f"auth_{email}")
            if not user_data:
                return None
            user = json.loads(user_data)
            if hashlib.sha256(password.encode()).hexdigest() == user["password"]:
                token = jwt.encode(
                    {"email": email, "role": user["role"], "exp": datetime.utcnow() + timedelta(hours=24)},
                    config.JWT_SECRET,
                    algorithm="HS256"
                )
                logger.info("User validated", email=email)
                return token
            return None
        except Exception as e:
            logger.error("User validation failed", email=email, error=str(e))
            raise

    async def validate_token(self, token: str) -> bool:
        try:
            payload = jwt.decode(token, config.JWT_SECRET, algorithms=["HS256"])
            user_data = self.get_secret(f"auth_{payload['email']}")
            if not user_data:
                return False
            user = json.loads(user_data)
            return payload["role"] in ["admin", "deployer"]
        except JWTError as e:
            logger.error("Token validation failed", error=str(e))
            return False

vault_manager = VaultManager()

# Database Initialization (Merge NovaShell’s Tables)
async def init_db():
    async with asyncpg.create_pool(config.DB_URL) as pool:
        async with pool.acquire() as conn:
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS nodes (
                    id SERIAL PRIMARY KEY,
                    node_id VARCHAR(64) UNIQUE NOT NULL,
                    public_key TEXT,
                    status VARCHAR(20) DEFAULT 'active',
                    last_seen TIMESTAMP DEFAULT NOW()
                );
                CREATE TABLE IF NOT EXISTS vaults (
                    id SERIAL PRIMARY KEY,
                    label VARCHAR(255) NOT NULL,
                    encrypted_content BYTEA NOT NULL,
                    encryption_method VARCHAR(50),
                    owner_node_id VARCHAR(64),
                    merkle_root VARCHAR(64),
                    integrity_hash VARCHAR(64),
                    created_at TIMESTAMP DEFAULT NOW()
                );
                CREATE TABLE IF NOT EXISTS ai_interactions (
                    id SERIAL PRIMARY KEY,
                    model_name VARCHAR(255),
                    prompt TEXT,
                    response TEXT,
                    created_at TIMESTAMP DEFAULT NOW()
                );
                CREATE TABLE IF NOT EXISTS blockchain_txns (
                    id SERIAL PRIMARY KEY,
                    tx_hash VARCHAR(66) UNIQUE NOT NULL,
                    from_address VARCHAR(42),
                    data_hash VARCHAR(64),
                    status VARCHAR(20) DEFAULT 'pending',
                    created_at TIMESTAMP DEFAULT NOW()
                );
                CREATE TABLE IF NOT EXISTS federated_rounds (
                    id SERIAL PRIMARY KEY,
                    round_id VARCHAR(64) UNIQUE NOT NULL,
                    model_id VARCHAR(64),
                    participants JSONB,
                    aggregated_weights BYTEA,
                    consensus_score FLOAT,
                    status VARCHAR(20) DEFAULT 'active',
                    created_at TIMESTAMP DEFAULT NOW()
                );
                CREATE TABLE IF NOT EXISTS swarm_intelligence (
                    id SERIAL PRIMARY KEY,
                    swarm_id VARCHAR(64) UNIQUE NOT NULL,
                    problem_definition JSONB,
                    best_solution JSONB,
                    convergence_history JSONB DEFAULT '[]',
                    status VARCHAR(20) DEFAULT 'running',
                    created_at TIMESTAMP DEFAULT NOW()
                );
                CREATE TABLE IF NOT EXISTS tasks (
                    id SERIAL PRIMARY KEY,
                    task_id VARCHAR(64) UNIQUE NOT NULL,
                    task_type VARCHAR(50),
                    payload JSONB,
                    status VARCHAR(20) DEFAULT 'pending',
                    result JSONB,
                    created_at TIMESTAMP DEFAULT NOW()
                );
                CREATE TABLE IF NOT EXISTS accounts (
                    platform TEXT,
                    email TEXT PRIMARY KEY,
                    username TEXT,
                    password TEXT,
                    status TEXT,
                    token TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                CREATE TABLE IF NOT EXISTS supplier_accounts (
                    supplier TEXT,
                    email TEXT,
                    password TEXT,
                    api_key TEXT,
                    net_terms TEXT,
                    PRIMARY KEY (supplier, email)
                );
                CREATE TABLE IF NOT EXISTS listings (
                    sku TEXT PRIMARY KEY,
                    platform TEXT,
                    title TEXT,
                    price REAL,
                    supplier TEXT,
                    status TEXT
                );
                CREATE TABLE IF NOT EXISTS orders (
                    order_id TEXT PRIMARY KEY,
                    platform TEXT,
                    sku TEXT,
                    buyer_name TEXT,
                    buyer_address TEXT,
                    status TEXT,
                    supplier TEXT,
                    fulfilled_at TIMESTAMP
                );
                CREATE TABLE IF NOT EXISTS users (
                    email TEXT PRIMARY KEY,
                    password TEXT,
                    role TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                CREATE TABLE IF NOT EXISTS bot_runs (
                    run_id TEXT PRIMARY KEY,
                    bot_name TEXT,
                    execution_time REAL,
                    errors INTEGER,
                    last_run TIMESTAMP,
                    status TEXT
                );
                CREATE INDEX IF NOT EXISTS idx_nodes_status ON nodes(status);
                CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks(status);
                CREATE INDEX IF NOT EXISTS idx_federated_rounds_status ON federated_rounds(status);
            """)
    logger.info("Database initialized successfully")

# Redis Client
redis_client = redis.Redis.from_url(config.REDIS_URL, decode_responses=True)

# Celery Setup
celery_app = Celery('omnimesh', broker=config.CELERY_BROKER_URL, backend=config.CELERY_RESULT_BACKEND)
celery_app.conf.task_reject_on_worker_lost = True
celery_app.conf.task_acks_late = True

# AI Routing Logic (Adopt NovaShell’s run_brain)
def run_brain(prompt: str) -> str:
    try:
        res = requests.post("http://localhost:11434/api/generate", json={
            "model": "deepseek-coder",
            "prompt": prompt,
            "stream": False
        }, timeout=20)
        return res.json().get("response", "")
    except Exception:
        groq_key = vault_manager.get_secret("groq_key") or os.getenv("GROQ_KEY")
        if not groq_key:
            raise Exception("No Groq key available")
        res = requests.post("https://api.groq.com/openai/v1/chat/completions", headers={
            "Authorization": f"Bearer {groq_key}"
        }, json={
            "model": "mixtral-8x7b",
            "messages": [{"role": "user", "content": prompt}]
        })
        return res.json()["choices"][0]["message"]["content"]

# Quantum Crypto (From OmniMesh)
class QuantumCrypto:
    def generate_keypair(self) -> tuple[bytes, bytes]:
        public_key, private_key = kyber_generate_keypair()
        return public_key, private_key

    def encrypt(self, message: bytes, public_key: bytes) -> bytes:
        ciphertext, _ = kyber_encrypt(public_key, message)
        return ciphertext

    def decrypt(self, ciphertext: bytes, private_key: bytes) -> bytes:
        try:
            plaintext = kyber_decrypt(private_key, ciphertext)
            return plaintext
        except Exception as e:
            logger.error(f"Decryption failed: {e}")
            raise HTTPException(status_code=500, detail="Decryption failed")

# AI Model Manager (Merge OmniMesh and NovaShell AI Capabilities)
class AIModelManager:
    def __init__(self, model_path: str, device: str):
        self.model_path = Path(model_path)
        self.model_path.mkdir(exist_ok=True)
        self.device = device
        self.pipelines = {}
        self.custom_models = {}
        self._initialize_models()

    def _initialize_models(self):
        try:
            self.pipelines["text_generation"] = pipeline(
                "text-generation",
                model=AutoModelForCausalLM.from_pretrained("gpt2-medium"),
                tokenizer=AutoTokenizer.from_pretrained("gpt2-medium"),
                device=0 if self.device == "cuda" else -1
            )
            self.pipelines["sentiment"] = pipeline("sentiment-analysis", device=0 if self.device == "cuda" else -1)
            self.pipelines["qa"] = pipeline("question-answering", device=0 if self.device == "cuda" else -1)
            self.pipelines["summarization"] = pipeline("summarization", device=0 if self.device == "cuda" else -1)
            self.pipelines["ner"] = pipeline("ner", aggregation_strategy="simple", device=0 if self.device == "cuda" else -1)

            class PredictionNet(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.lstm = nn.LSTM(10, 64, batch_first=True)
                    self.fc = nn.Linear(64, 1)
                def forward(self, x):
                    x, _ = self.lstm(x)
                    return self.fc(x[:, -1, :])

            self.custom_models["prediction"] = PredictionNet().to(self.device)
            self.custom_models["optimizer"] = optim.Adam(self.custom_models["prediction"].parameters())
            logger.info("AI models initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize AI models: {e}")
            raise

    async def generate_text(self, prompt: str, max_length: int = 100) -> str:
        try:
            result = self.pipelines["text_generation"](prompt, max_length=max_length, num_return_sequences=1, temperature=0.7)
            return result[0]["generated_text"]
        except Exception as e:
            logger.error(f"Text generation failed: {e}")
            raise HTTPException(status_code=500, detail="Text generation failed")

    async def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        try:
            result = self.pipelines["sentiment"](text)
            return {"label": result[0]["label"], "confidence": result[0]["score"]}
        except Exception as e:
            logger.error(f"Sentiment analysis failed: {e}")
            raise HTTPException(status_code=500, detail="Sentiment analysis failed")

    async def answer_question(self, question: str, context: str) -> Dict[str, Any]:
        try:
            result = self.pipelines["qa"](question=question, context=context)
            return {"answer": result["answer"], "confidence": result["score"]}
        except Exception as e:
            logger.error(f"Question answering failed: {e}")
            raise HTTPException(status_code=500, detail="Question answering failed")

    async def summarize_text(self, text: str, max_length: int = 150) -> Dict[str, Any]:
        try:
            if len(text.split()) < 30:
                return {"summary": text, "method": "original"}
            result = self.pipelines["summarization"](text, max_length=max_length, min_length=30)
            return {"summary": result[0]["summary_text"], "method": "abstractive"}
        except Exception as e:
            logger.error(f"Summarization failed: {e}")
            raise HTTPException(status_code=500, detail="Summarization failed")

    async def extract_entities(self, text: str) -> List[Dict[str, Any]]:
        try:
            return self.pipelines["ner"](text)
        except Exception as e:
            logger.error(f"NER failed: {e}")
            raise HTTPException(status_code=500, detail="NER failed")

    async def predict(self, data: List[List[float]]) -> List[float]:
        try:
            self.custom_models["prediction"].eval()
            with torch.no_grad():
                tensor_data = torch.FloatTensor(data).unsqueeze(0).to(self.device)
                prediction = self.custom_models["prediction"](tensor_data)
                return prediction.cpu().numpy().tolist()[0]
        except Exception as e:
            logger.error(f"Prediction failed: {e}")
            raise HTTPException(status_code=500, detail="Prediction failed")

    async def generate_description(self, title: str) -> str:
        blob = TextBlob(title)
        adjectives = ["Premium", "High-Quality", "Durable", "Stylish"]
        adverbs = ["Effortlessly", "Seamlessly", "Perfectly"]
        return f"{random.choice(adverbs)} enhance your experience with this {random.choice(adjectives)} {blob.noun_phrases[0]}."

# Federated Learning Manager (From OmniMesh)
class FederatedLearningManager:
    def __init__(self, model_path: str, device: str):
        self.model_path = Path(model_path)
        self.device = device
        self.active_rounds = {}

    async def create_federated_round(self, model_architecture: Dict, participants: List[str]) -> str:
        try:
            round_id = str(uuid.uuid4())
            class SimpleNN(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.fc = nn.Linear(model_architecture.get("input_size", 100), model_architecture.get("output_size", 10))
                def forward(self, x):
                    return self.fc(x)
            base_model = SimpleNN().to(self.device)
            self.active_rounds[round_id] = {
                "model": base_model,
                "participants": participants,
                "received_updates": {},
                "status": "waiting_for_updates"
            }
            async with asyncpg.create_pool(config.DB_URL) as pool:
                async with pool.acquire() as conn:
                    await conn.execute(
                        "INSERT INTO federated_rounds (round_id, participants, status, model_id) VALUES ($1, $2, $3, $4)",
                        round_id, json.dumps(participants), "active", f"fed_model_{round_id}"
                    )
            logger.info(f"Created federated round {round_id} with {len(participants)} participants")
            return round_id
        except Exception as e:
            logger.error(f"Federated round creation failed: {e}")
            raise HTTPException(status_code=500, detail="Invalid model architecture or database error")

    async def submit_model_update(self, round_id: str, node_id: str, model_weights: bytes) -> bool:
        try:
            if round_id not in self.active_rounds or node_id not in self.active_rounds[round_id]["participants"]:
                raise HTTPException(status_code=403, detail="Invalid round or node")
            weights = pickle.loads(model_weights)
            self.active_rounds[round_id]["received_updates"][node_id] = weights
            if len(self.active_rounds[round_id]["received_updates"]) == len(self.active_rounds[round_id]["participants"]):
                await self._aggregate_model_updates(round_id)
            logger.info(f"Model update submitted for round {round_id} by node {node_id}")
            return True
        except Exception as e:
            logger.error(f"Model update submission failed: {e}")
            raise HTTPException(status_code=500, detail="Failed to submit model update")

    async def _aggregate_model_updates(self, round_id: str):
        try:
            updates = self.active_rounds[round_id]["received_updates"]
            model = self.active_rounds[round_id]["model"]
            state_dict = model.state_dict()
            for key in state_dict.keys():
                param_sum = None
                for node_id in updates:
                    param = torch.tensor(updates[node_id][key])
                    param_sum = param if param_sum is None else param_sum + param
                state_dict[key] = param_sum / len(updates)
            model.load_state_dict(state_dict)
            aggregated_weights = {k: v.cpu().numpy() for k, v in state_dict.items()}
            consensus_score = np.mean([np.linalg.norm(list(updates[node_id].values())[0]) for node_id in updates])
            async with asyncpg.create_pool(config.DB_URL) as pool:
                async with pool.acquire() as conn:
                    await conn.execute(
                        "UPDATE federated_rounds SET aggregated_weights = $1, consensus_score = $2, status = $3 WHERE round_id = $4",
                        pickle.dumps(aggregated_weights), float(consensus_score), "completed", round_id
                    )
            self.active_rounds[round_id]["status"] = "completed"
            logger.info(f"Aggregated model for round {round_id} with consensus score {consensus_score}")
        except Exception as e:
            logger.error(f"Model aggregation failed: {e}")
            raise HTTPException(status_code=500, detail="Failed to aggregate model updates")

# Swarm Intelligence Engine (From OmniMesh)
class SwarmIntelligenceEngine:
    def __init__(self):
        self.active_swarms = {}
        self.optimization_functions = {
            "sphere": lambda x: sum(xi**2 for xi in x),
            "rastrigin": lambda x: 10 * len(x) + sum(xi**2 - 10 * np.cos(2 * np.pi * xi) for xi in x)
        }

    async def create_swarm(self, problem: str, dimensions: int, agents: int) -> str:
        try:
            if problem not in self.optimization_functions:
                raise HTTPException(status_code=400, detail="Invalid problem. Supported problems: sphere, rastrigin")
            if dimensions < 1 or agents < 1:
                raise HTTPException(status_code=400, detail="Dimensions and agents must be positive integers")
            swarm_id = str(uuid.uuid4())
            self.active_swarms[swarm_id] = {
                "problem": problem,
                "positions": np.random.uniform(-5, 5, (agents, dimensions)),
                "velocities": np.random.uniform(-1, 1, (agents, dimensions)),
                "best_positions": np.random.uniform(-5, 5, (agents, dimensions)),
                "best_fitness": np.array([float('inf')] * agents),
                "global_best_position": np.zeros(dimensions),
                "global_best_fitness": float('inf'),
                "status": "running",
                "convergence_history": []
            }
            async with asyncpg.create_pool(config.DB_URL) as pool:
                async with pool.acquire() as conn:
                    await conn.execute(
                        "INSERT INTO swarm_intelligence (swarm_id, problem_definition, status) VALUES ($1, $2, $3)",
                        swarm_id, json.dumps({"problem": problem, "dimensions": dimensions, "agents": agents}), "running"
                    )
            logger.info(f"Created swarm {swarm_id} with {agents} agents")
            return swarm_id
        except Exception as e:
            logger.error(f"Swarm creation failed: {e}")
            raise HTTPException(status_code=500, detail="Failed to create swarm")

    async def step_swarm(self, swarm_id: str) -> Dict[str, Any]:
        try:
            if swarm_id not in self.active_swarms:
                raise HTTPException(status_code=404, detail="Swarm not found")
            swarm = self.active_swarms[swarm_id]
            if swarm["status"] != "running":
                raise HTTPException(status_code=400, detail="Swarm is not in running state")
            w, c1, c2 = 0.5, 1.5, 1.5  # PSO parameters
            for i in range(len(swarm["positions"])):
                r1, r2 = np.random.random(2)
                swarm["velocities"][i] = (
                    w * swarm["velocities"][i] +
                    c1 * r1 * (swarm["best_positions"][i] - swarm["positions"][i]) +
                    c2 * r2 * (swarm["global_best_position"] - swarm["positions"][i])
                )
                swarm["positions"][i] += swarm["velocities"][i]
                fitness = self.optimization_functions[swarm["problem"]](swarm["positions"][i])
                if fitness < swarm["best_fitness"][i]:
                    swarm["best_fitness"][i] = fitness
                    swarm["best_positions"][i] = swarm["positions"][i].copy()
                if fitness < swarm["global_best_fitness"]:
                    swarm["global_best_fitness"] = fitness
                    swarm["global_best_position"] = swarm["positions"][i].copy()
            swarm["convergence_history"].append({"fitness": swarm["global_best_fitness"], "timestamp": datetime.utcnow().isoformat()})
            if len(swarm["convergence_history"]) > 100:  # Limit history size
                swarm["convergence_history"] = swarm["convergence_history"][-50:]
            async with asyncpg.create_pool(config.DB_URL) as pool:
                async with pool.acquire() as conn:
                    await conn.execute(
                        "UPDATE swarm_intelligence SET best_solution = $1, convergence_history = $2 WHERE swarm_id = $3",
                        json.dumps({"position": swarm["global_best_position"].tolist(), "fitness": swarm["global_best_fitness"]}),
                        json.dumps(swarm["convergence_history"]),
                        swarm_id
                    )
            logger.info(f"Stepped swarm {swarm_id}")
            return {"best_fitness": swarm["global_best_fitness"], "best_position": swarm["global_best_position"].tolist()}
        except Exception as e:
            logger.error(f"Swarm step failed: {e}")
            raise HTTPException(status_code=500, detail="Failed to step swarm")

# Blockchain Manager (From OmniMesh)
class BlockchainManager:
    def __init__(self, rpc_url: str):
        self.w3 = Web3(HTTPProvider(rpc_url))
        if not self.w3.is_connected():
            raise HTTPException(status_code=500, detail="Failed to connect to Ethereum network")
        self.contract_address = config.CONTRACT_ADDRESS
        self.contract_abi = [
            {"inputs": [{"name": "data", "type": "string"}], "name": "storeData", "outputs": [], "type": "function"}
        ]
        self.contract = self.w3.eth.contract(address=self.contract_address, abi=self.contract_abi)
        self.account = self.w3.eth.account.create()
        self.private_key = self.account.key.hex()

    async def submit_data(self, data: Dict, background_tasks: BackgroundTasks) -> str:
        try:
            data_str = json.dumps(data)
            tx = self.contract.functions.storeData(data_str).build_transaction({
                'from': self.account.address,
                'nonce': self.w3.eth.get_transaction_count(self.account.address),
                'gas': 200000,
                'gasPrice': self.w3.to_wei('50', 'gwei')
            })
            signed_tx = self.w3.eth.account.sign_transaction(tx, self.private_key)
            tx_hash = self.w3.eth.send_raw_transaction(signed_tx.rawTransaction)
            tx_hash_hex = tx_hash.hex()
            data_hash = hashlib.sha256(data_str.encode()).hexdigest()
            async with asyncpg.create_pool(config.DB_URL) as pool:
                async with pool.acquire() as conn:
                    await conn.execute(
                        "INSERT INTO blockchain_txns (tx_hash, from_address, data_hash, status) VALUES ($1, $2, $3, $4)",
                        tx_hash_hex, self.account.address, data_hash, "pending"
                    )
            background_tasks.add_task(self._poll_transaction, tx_hash_hex)
            logger.info(f"Submitted blockchain transaction: {tx_hash_hex}")
            return tx_hash_hex
        except Exception as e:
            logger.error(f"Blockchain submission failed: {e}")
            raise HTTPException(status_code=500, detail="Failed to submit to blockchain")

    async def _poll_transaction(self, tx_hash: str):
        try:
            max_attempts = 30
            for _ in range(max_attempts):
                receipt = self.w3.eth.get_transaction_receipt(tx_hash)
                if receipt:
                    status = "confirmed" if receipt.status == 1 else "failed"
                    async with asyncpg.create_pool(config.DB_URL) as pool:
                        async with pool.acquire() as conn:
                            await conn.execute(
                                "UPDATE blockchain_txns SET status = $1 WHERE tx_hash = $2",
                                status, tx_hash
                            )
                    logger.info(f"Transaction {tx_hash} {status}")
                    return
                await asyncio.sleep(10)
            async with asyncpg.create_pool(config.DB_URL) as pool:
                async with pool.acquire() as conn:
                    await conn.execute(
                        "UPDATE blockchain_txns SET status = $1 WHERE tx_hash = $2",
                        "timeout", tx_hash
                    )
            logger.warning(f"Transaction {tx_hash} timed out")
        except Exception as e:
            logger.error(f"Transaction polling failed for {tx_hash}: {e}")

# Mesh Node (From OmniMesh)
class MeshNode:
    def __init__(self, node_id: str, port: int):
        self.node_id = node_id
        self.port = port
        self.peers = {}
        self.message_queue = asyncio.Queue()

    async def start(self):
        server = await asyncio.start_server(self.handle_connection, '0.0.0.0', self.port)
        asyncio.create_task(self.process_messages())
        logger.info(f"Mesh node {self.node_id} started on port {self.port}")
        return server

    async def handle_connection(self, reader, writer):
        try:
            data = await reader.read(8192)
            if data:
                message = pickle.loads(data)
                await self.message_queue.put(message)
                writer.write(pickle.dumps({"type": "ack", "node_id": self.node_id}))
                await writer.drain()
        except Exception as e:
            logger.error(f"Mesh connection error: {e}")
        finally:
            writer.close()
            await writer.wait_closed()

    async def process_messages(self):
        while True:
            message = await self.message_queue.get()
            logger.info(f"Processed mesh message: {message}")
            if message.get("type") == "ping":
                logger.info(f"Received ping from {message.get('source')}")

# E-Commerce Utilities (From NovaShell)
ua = UserAgent()
async def get_random_user_agent() -> str:
    return ua.random

class ProxyManager:
    def __init__(self):
        self.proxies = asyncio.run(self.fetch_proxy_list())
        self.session_proxies = {}

    def rotate(self, session_id: str) -> Dict[str, str]:
        if not self.proxies:
            logger.warning("No proxies available")
            return {}
        if session_id not in self.session_proxies:
            self.session_proxies[session_id] = random.choice(self.proxies)
        proxy = self.session_proxies[session_id]
        return {'http': f'http://{proxy}', 'https': f'http://{proxy}'}

    async def fetch_proxy_list(self) -> list:
        async with aiohttp.ClientSession() as session:
            url = "https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=10000"
            async with session.get(url) as resp:
                if resp.status == 200:
                    return (await resp.text()).splitlines()[:50]
                return []

proxy_manager = ProxyManager()

async def human_like_typing(element, text):
    for char in text:
        element.send_keys(char)
        await asyncio.sleep(random.uniform(0.05, 0.3))

async def generate_email() -> str:
    domain = os.getenv("DOMAIN", "gmail.com")
    user = ''.join(random.choices(string.ascii_lowercase + string.digits, k=10))
    return f"{user}@{domain}"

async def solve_captcha(site_key: str, url: str) -> Optional[str]:
    async with aiohttp.ClientSession() as session:
        captcha_url = "http://2captcha.com/in.php"
        params = {"key": os.getenv("CAPTCHA_API_KEY"), "method": "userrecaptcha", "googlekey": site_key, "pageurl": url}
        async with session.post(captcha_url, data=params) as resp:
            text = await resp.text()
            if "OK" not in text:
                return None
            captcha_id = text.split("|")[1]
            for _ in range(10):
                await asyncio.sleep(5)
                async with session.get(f"http://2captcha.com/res.php?key={os.getenv('CAPTCHA_API_KEY')}&action=get&id={captcha_id}") as resp:
                    text = await resp.text()
                    if "OK" in text:
                        return text.split("|")[1]
            return None

async def get_virtual_phone() -> str:
    twilio_key = os.getenv("TWILIO_API_KEY")
    if not twilio_key:
        return f"+1555{random.randint(1000000, 9999999)}"
    async with aiohttp.ClientSession(headers={"Authorization": f"Basic {base64.b64encode(twilio_key.encode()).decode()}"}) as session:
        url = f"https://api.twilio.com/2010-04-01/Accounts/{twilio_key.split(':')[0]}/IncomingPhoneNumbers.json"
        async with session.post(url, data={"AreaCode": "555"}) as resp:
            if resp.status == 201:
                return (await resp.json())["phone_number"]
            return f"+1555{random.randint(1000000, 9999999)}"

async def fetch_otp(email: str, subject_filter: str = "verification") -> str:
    mail = imaplib.IMAP4_SSL(config.EMAIL_PROVIDER)
    mail.login(config.EMAIL_USER, config.EMAIL_PASS)
    mail.select("inbox")
    for _ in range(10):
        status, messages = mail.search(None, f'(UNSEEN SUBJECT "{subject_filter}")')
        if status == "OK" and messages[0]:
            latest_email_id = messages[0].split()[-1]
            _, msg_data = mail.fetch(latest_email_id, "(RFC822)")
            raw_email = msg_data[0][1]
            email_message = email.message_from_bytes(raw_email)
            for part in email_message.walk():
                if part.get_content_type() == "text/plain":
                    body = part.get_payload(decode=True).decode()
                    otp = re.search(r'\b\d{6}\b', body)
                    if otp:
                        mail.logout()
                        return otp.group()
        await asyncio.sleep(5)
    mail.logout()
    raise Exception("OTP retrieval failed")

# Celery Tasks (Merge OmniMesh and NovaShell)
async def track_bot_run(bot_name: str, execution_time: float, errors: int, status: str):
    run_id = str(uuid.uuid4())
    async with asyncpg.create_pool(config.DB_URL) as pool:
        async with pool.acquire() as conn:
            await conn.execute(
                "INSERT INTO bot_runs (run_id, bot_name, execution_time, errors, last_run, status) VALUES ($1, $2, $3, $4, $5, $6)",
                run_id, bot_name, execution_time, errors, datetime.utcnow(), status
            )

@celery_app.task
def process_task(task_id: str, task_type: str, payload: Dict):
    async def run():
        try:
            await asyncio.sleep(5)  # Simulate work
            result = {"result": f"Processed {task_type} with payload {json.dumps(payload)}"}
            async with asyncpg.create_pool(config.DB_URL) as pool:
                async with pool.acquire() as conn:
                    await conn.execute(
                        "UPDATE tasks SET status = $1, result = $2 WHERE task_id = $3",
                        "completed", json.dumps(result), task_id
                    )
            logger.info(f"Processed task {task_id}")
        except Exception as e:
            logger.error(f"Task processing failed: {e}")
            async with asyncpg.create_pool(config.DB_URL) as pool:
                async with pool.acquire() as conn:
                    await conn.execute(
                        "UPDATE tasks SET status = $1, result = $2 WHERE task_id = $3",
                        "failed", json.dumps({"error": str(e)}), task_id
                    )
    asyncio.run(run())
    return {"task_id": task_id, "status": "completed"}

@celery_app.task(bind=True)
@retry(stop=stop_after_attempt(5))
async def create_platform_account(self, platform: str, index: int) -> Tuple[Optional[str], Optional[str]]:
    try:
        email = await generate_email()
        username = f"{platform.lower()}user{index}{random.randint(100, 999)}"
        password = ''.join(random.choices(string.ascii_letters + string.digits, k=12))
        phone = await get_virtual_phone()
        signup_urls = {
            "eBay": "https://signup.ebay.com/pa/register",
            "Amazon": "https://sellercentral.amazon.com/register",
            "Walmart": "https://marketplace.walmart.com/us/seller-signup",
            "Etsy": "https://www.etsy.com/sell",
            "Shopify": "https://www.shopify.com/signup"
        }
        session_id = f"{platform}_{email}"
        token = None
        if platform == "eBay":
            payload = {"email": email, "password": password, "firstName": f"User{index}", "lastName": "Auto", "phone": phone}
            headers = {"User-Agent": await get_random_user_agent()}
            async with aiohttp.ClientSession(headers=headers) as session:
                async with session.get(signup_urls[platform], proxy=proxy_manager.rotate(session_id)["http"]) as resp:
                    captcha_response = await solve_captcha(os.getenv("EBAY_SITE_KEY"), signup_urls[platform])
                    if captcha_response:
                        payload["g-recaptcha-response"] = captcha_response
                    async with session.post(signup_urls[platform], data=payload, proxy=proxy_manager.rotate(session_id)["http"]) as resp:
                        if resp.status != 200:
                            raise Exception("eBay signup failed")
                        token = await fetch_ebay_token(email, password)
        else:
            options = Options()
            options.add_argument("--headless")
            options.add_argument(f"--user-agent={await get_random_user_agent()}")
            proxy = proxy_manager.rotate(session_id)
            if proxy:
                options.add_argument(f'--proxy-server={proxy["http"]}')
            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
            try:
                driver.get(signup_urls[platform])
                email_field = driver.find_element(By.CSS_SELECTOR, "input[type='email']")
                password_field = driver.find_element(By.CSS_SELECTOR, "input[type='password']")
                await human_like_typing(email_field, email)
                await human_like_typing(password_field, password)
                driver.find_element(By.XPATH, "//button[@type='submit']").click()
                time.sleep(5)
                otp = await fetch_otp(email, f"{platform} Verification")
                if otp:
                    otp_field = driver.find_element(By.CSS_SELECTOR, "input[placeholder*='code']")
                    await human_like_typing(otp_field, otp)
                    driver.find_element(By.XPATH, "//button[@type='submit']").click()
                    token = driver.find_element(By.CSS_SELECTOR, "input[name='api_token']").get_attribute("value")
            finally:
                driver.quit()
        async with asyncpg.create_pool(config.DB_URL) as pool:
            async with pool.acquire() as conn:
                await conn.execute(
                    "INSERT INTO accounts (platform, email, username, password, status, token) VALUES ($1, $2, $3, $4, $5, $6) ON CONFLICT (email) DO NOTHING",
                    platform, email, username, password, "active", token
                )
        vault_manager.store_secret(f"{platform}_EMAIL", email)
        vault_manager.store_secret(f"{platform}_TOKEN", token)
        return username, token
    except Exception as e:
        logger.error(f"Platform account creation failed: {e}")
        raise self.retry(exc=e)

async def fetch_ebay_token(email: str, password: str) -> str:
    options = Options()
    options.add_argument("--headless")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    try:
        driver.get("https://signin.ebay.com")
        await human_like_typing(driver.find_element(By.ID, "userid"), email)
        await human_like_typing(driver.find_element(By.ID, "pass"), password)
        driver.find_element(By.ID, "sgnBt").click()
        driver.get("https://developer.ebay.com/my/auth?env=production")
        return driver.find_element(By.XPATH, "//textarea[contains(@class, 'oauth-token')]").text
    finally:
        driver.quit()

@retry(stop=stop_after_attempt(3))
async def fetch_products() -> list:
    suppliers = config.SUPPLIERS
    all_products = []
    for supplier in suppliers:
        cached = await redis_client.get(f"products:{supplier}")
        if cached:
            all_products.extend(json.loads(cached))
            continue
        api_key = vault_manager.get_secret(f"{supplier}_API_KEY")
        products = []  # Simplified for brevity (implement real API calls as needed)
        await redis_client.setex(f"products:{supplier}", 3600, json.dumps(products))
        all_products.extend(products)
    return all_products

@retry(stop=stop_after_attempt(3))
async def list_product_on_platform(product: Dict, platform: str) -> bool:
    try:
        token = vault_manager.get_secret(f"{platform}_TOKEN")
        if not token:
            raise ValueError(f"No token found for {platform}")
        headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json", "User-Agent": await get_random_user_agent()}
        desc = await ai_manager.generate_description(product["title"])
        url = f"https://api.{platform.lower()}.com/sell/inventory/v1/offer"
        payload = {
            "sku": product["sku"],
            "marketplaceId": f"{platform.upper()}_US",
            "listingDescription": desc,
            "pricingSummary": {"price": {"value": str(product["price"]), "currency": "USD"}},
            "availableQuantity": product["quantity"]
        }
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.post(url, json=payload) as resp:
                if resp.status in [200, 201]:
                    async with asyncpg.create_pool(config.DB_URL) as pool:
                        async with pool.acquire() as conn:
                            await conn.execute(
                                "INSERT INTO listings (sku, platform, title, price, supplier, status) VALUES ($1, $2, $3, $4, $5, $6) ON CONFLICT (sku) DO UPDATE SET status = $6",
                                product["sku"], platform, product["title"], product["price"], product["supplier"], "active"
                            )
                    logger.info(f"Listed {product['title']} on {platform}", price=product["price"])
                    return True
                logger.error(f"Failed to list on {platform}: {await resp.text()}")
                raise Exception(f"Failed to list on {platform}")
    except Exception as e:
        logger.error(f"Listing failed: {str(e)}")
        raise e

@retry(stop=stop_after_attempt(3))
async def fulfill_order(order_id: str, platform: str, sku: str, buyer_name: str, buyer_address: str, supplier: str) -> bool:
    try:
        async with asyncpg.create_pool(config.DB_URL) as pool:
            async with pool.acquire() as conn:
                listing = await conn.fetchrow("SELECT * FROM listings WHERE sku = $1 AND platform = $2", sku, platform)
                if not listing:
                    logger.error(f"No matching listing found for SKU {sku} on {platform}")
                    raise Exception("Listing not found")
                api_key = vault_manager.get_secret(f"{supplier}_API_KEY")
                if not api_key:
                    logger.error(f"No API key found for {supplier}")
                    raise Exception("API key missing")
                urls = {
                    "CJ Dropshipping": "https://developers.cjdropshipping.com/api2.0/order/create",
                    "AliExpress": "https://api.aliexpress.com/v1/order/place"
                }
                headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json", "User-Agent": await get_random_user_agent()}
                payload = {
                    "order_id": order_id,
                    "sku": sku,
                    "buyer_name": buyer_name,
                    "buyer_address": buyer_address,
                    "quantity": 1
                }
                async with aiohttp.ClientSession(headers=headers) as session:
                    async with session.post(urls[supplier], json=payload) as resp:
                        if resp.status == 200:
                            await conn.execute(
                                "UPDATE orders SET status = 'fulfilled', fulfilled_at = CURRENT_TIMESTAMP WHERE order_id = $1",
                                order_id
                            )
                            logger.info(f"Fulfilled order {order_id} via {supplier}")
                            return True
                        logger.error(f"Failed to fulfill order {order_id}: {await resp.text()}")
                        raise Exception("Order fulfillment failed")
    except Exception as e:
        logger.error(f"Fulfillment error for order {order_id}: {str(e)}")
        raise e

# Bot Agent (Integrate NovaShell’s nova-agent.py Logic)
async def run_bot(bot_path: str, bot_name: str):
    try:
        bot_module = bot_name.replace('.py', '')
        sys.path.insert(0, str(Path(bot_path).parent))
        module = import_module(bot_module)
        start_time = time.time()
        module.main()  # Assumes bot has a main() function
        execution_time = time.time() - start_time
        await redis_client.publish(f"nova:logs_{bot_name}", json.dumps({"status": "success", "execution_time": execution_time}))
        await track_bot_run(bot_name, execution_time, 0, "success")
        logger.info("Bot executed successfully", bot=bot_name, execution_time=execution_time)
    except Exception as e:
        await redis_client.publish(f"nova:logs_{bot_name}", json.dumps({"status": "error", "error": str(e)}))
        await track_bot_run(bot_name, 0, 1, "failed")
        logger.error("Bot execution failed", bot=bot_name, error=str(e))
        raise

async def bot_listener():
    pubsub = redis_client.pubsub()
    pubsub.subscribe("nova:deploy:*")
    logger.info("Bot listener started, listening for deploy tasks")
    async for message in pubsub.listen():
        if message["type"] == "message":
            try:
                channel = message["channel"]
                bot_name = channel.split(":")[2]
                data = json.loads(message["data"])
                bot_path = data["path"]
                logger.info("Received deploy task", bot=bot_name, path=bot_path)
                await run_bot(bot_path, bot_name)
            except Exception as e:
                logger.error("Error processing deploy task", error=str(e))
                continue

# FastAPI App
app = FastAPI(title="OmniMesh + NovaShell", version="2.1.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=[config.FRONTEND_URL],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)
security = HTTPBearer()
quantum_crypto = QuantumCrypto()
ai_manager = AIModelManager(config.MODEL_PATH, config.TORCH_DEVICE)
federated_manager = FederatedLearningManager(config.MODEL_PATH, config.TORCH_DEVICE)
swarm_engine = SwarmIntelligenceEngine()
blockchain_manager = BlockchainManager(config.ETH_RPC)
mesh_node = MeshNode(config.NODE_ID, config.MESH_PORT)

# Pydantic Models (Merge OmniMesh and NovaShell Models)
class TokenRequest(BaseModel):
    email: str
    password: str

class EncryptRequest(BaseModel):
    label: str = Field(..., min_length=1, max_length=255)
    data: Dict

class AIRequest(BaseModel):
    prompt: str = Field(..., min_length=1)
    max_length: int = Field(100, ge=10, le=500)

class SentimentRequest(BaseModel):
    text: str = Field(..., min_length=1)

class QuestionRequest(BaseModel):
    question: str = Field(..., min_length=1)
    context: str = Field(..., min_length=1)

class SummarizeRequest(BaseModel):
    text: str = Field(..., min_length=1)
    max_length: int = Field(150, ge=30, le=500)

class NERRequest(BaseModel):
    text: str = Field(..., min_length=1)

class PredictRequest(BaseModel):
    data: List[List[float]]

class FederatedRoundRequest(BaseModel):
    model_architecture: Dict
    participants: List[str] = Field(..., min_items=1)

class FederatedUpdateRequest(BaseModel):
    round_id: str = Field(..., min_length=36, max_length=36)
    model_weights: bytes

class SwarmRequest(BaseModel):
    problem: str = Field(..., pattern="^(sphere|rastrigin)$")
    dimensions: int = Field(..., ge=1)
    agents: int = Field(..., ge=1)

class SwarmStepRequest(BaseModel):
    swarm_id: str = Field(..., min_length=36, max_length=36)

class BlockchainSubmitRequest(BaseModel):
    data: Dict

class TaskRequest(BaseModel):
    task_type: str = Field(..., min_length=1, max_length=50)
    payload: Dict

class Product(BaseModel):
    title: str
    sku: str
    cost: float
    price: float
    url: str
    quantity: int
    supplier: str

class AccountInput(BaseModel):
    email: str
    password: str
    phone: str

    @validator('email')
    def email_valid(cls, v):
        if '@' not in v or '.' not in v:
            raise ValueError('Invalid email format')
        return v

class OrderFulfillRequest(BaseModel):
    order_id: str
    platform: str
    sku: str
    buyer_name: str
    buyer_address: str
    supplier: str

class BotDeployRequest(BaseModel):
    bot_name: str
    bot_path: str

# Authentication
async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        if not await vault_manager.validate_token(credentials.credentials):
            raise HTTPException(status_code=401, detail="Invalid token")
        payload = jwt.decode(credentials.credentials, config.JWT_SECRET, algorithms=["HS256"])
        email: str = payload.get("email")
        if email is None:
            raise HTTPException(status_code=401, detail="Invalid token")
        return email
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")

# Endpoints (Merge OmniMesh and NovaShell)
@app.on_event("startup")
async def startup_event():
    await init_db()
    asyncio.create_task((await mesh_node.start()).serve_forever())
    asyncio.create_task(bot_listener())
    asyncio.create_task(ping_nodes())
    asyncio.create_task(update_metrics())
    logger.info("OmniMesh + NovaShell backend started")

@app.post("/auth/register")
async def register(email: str, password: str, role: str = "user"):
    try:
        await vault_manager.register_user(email, password, role)
        logger.info("User registered successfully", email=email)
        return {"message": "User registered"}
    except Exception as e:
        logger.error("User registration failed", error=str(e))
        raise HTTPException(status_code=500, detail=f"Registration failed: {str(e)}")

@app.post("/auth/login")
async def login(form_data: TokenRequest):
    try:
        token = await vault_manager.validate_user(form_data.email, form_data.password)
        if not token:
            logger.warning("Invalid login attempt", email=form_data.email)
            raise HTTPException(status_code=401, detail="Invalid credentials")
        logger.info("User logged in", email=form_data.email)
        return {"access_token": token, "token_type": "bearer"}
    except Exception as e:
        logger.error("Login failed", error=str(e))
        raise HTTPException(status_code=500, detail=f"Login failed: {str(e)}")

@app.post("/api/crypto/encrypt", dependencies=[Depends(get_current_user)])
async def encrypt_data(req: EncryptRequest):
    try:
        public_key, private_key = quantum_crypto.generate_keypair()
        data_bytes = json.dumps(req.data).encode()
        ciphertext = quantum_crypto.encrypt(data_bytes, public_key)
        merkle = MerkleTools()
        merkle.add_leaf(ciphertext.hex())
        merkle.make_tree()
        integrity_hash = hashlib.sha256(ciphertext).hexdigest()
        async with asyncpg.create_pool(config.DB_URL) as pool:
            async with pool.acquire() as conn:
                await conn.execute(
                    "INSERT INTO vaults (label, encrypted_content, encryption_method, owner_node_id, merkle_root, integrity_hash) "
                    "VALUES ($1, $2, $3, $4, $5, $6)",
                    req.label, ciphertext, "kyber512", config.NODE_ID, merkle.get_merkle_root(), integrity_hash
                )
        logger.info(f"Encrypted data for vault {req.label}")
        return {"ciphertext": ciphertext.hex(), "label": req.label}
    except ValueError as ve:
        logger.error(f"Encryption failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Encryption failed: {e}")
        raise HTTPException(status_code=500, detail="Encryption failed")

@app.post("/api/ai/generate", dependencies=[Depends(get_current_user)])
async def generate_text(req: AIRequest):
    try:
        response = await ai_manager.generate_text(req.prompt, req.max_length)
        async with asyncpg.create_pool(config.DB_URL) as pool:
            async with pool.acquire() as conn:
                await conn.execute(
                    "INSERT INTO ai_interactions (model_name, prompt, response) VALUES ($1, $2, $3)",
                    "gpt2-medium", req.prompt, response
                )
        logger.info(f"Generated text for prompt: {req.prompt[:50]}...")
        return {"result": response}
    except ValueError as ve:
        logger.error(f"Text generation failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Text generation failed: {e}")
        raise HTTPException(status_code=500, detail="Text generation failed")

@app.post("/api/ai/sentiment", dependencies=[Depends(get_current_user)])
async def analyze_sentiment(req: SentimentRequest):
    try:
        result = await ai_manager.analyze_sentiment(req.text)
        logger.info(f"Sentiment analyzed for text: {req.text[:50]}...")
        return result
    except ValueError as ve:
        logger.error(f"Sentiment analysis failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Sentiment analysis failed: {e}")
        raise HTTPException(status_code=500, detail="Sentiment analysis failed")

@app.post("/api/ai/question", dependencies=[Depends(get_current_user)])
async def answer_question(req: QuestionRequest):
    try:
        result = await ai_manager.answer_question(req.question, req.context)
        logger.info(f"Question answered: {req.question[:50]}...")
        return result
    except ValueError as ve:
        logger.error(f"Question answering failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Question answering failed: {e}")
        raise HTTPException(status_code=500, detail="Question answering failed")

@app.post("/api/ai/summarize", dependencies=[Depends(get_current_user)])
async def summarize_text(req: SummarizeRequest):
    try:
        result = await ai_manager.summarize_text(req.text, req.max_length)
        logger.info(f"Summarized text: {req.text[:50]}...")
        return result
    except ValueError as ve:
        logger.error(f"Summarization failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Summarization failed: {e}")
        raise HTTPException(status_code=500, detail="Summarization failed")

@app.post("/api/ai/ner", dependencies=[Depends(get_current_user)])
async def extract_entities(req: NERRequest):
    try:
        result = await ai_manager.extract_entities(req.text)
        logger.info(f"Entities extracted from text: {req.text[:50]}...")
        return result
    except ValueError as ve:
        logger.error(f"NER failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"NER failed: {e}")
        raise HTTPException(status_code=500, detail="NER failed")

@app.post("/api/ai/predict", dependencies=[Depends(get_current_user)])
async def predict(req: PredictRequest):
    try:
        if not req.data or not all(isinstance(sublist, list) for sublist in req.data):
            raise ValueError("Data must be a non-empty list of lists of floats")
        result = await ai_manager.predict(req.data)
        logger.info(f"Prediction made for data shape: {len(req.data)}")
        return {"predictions": result}
    except ValueError as ve:
        logger.error(f"Prediction failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Prediction failed: {e}")
        raise HTTPException(status_code=500, detail="Prediction failed")

@app.post("/api/brain/assign", dependencies=[Depends(get_current_user)])
async def assign_brain_task(payload: dict):
    try:
        prompt = payload.get("prompt", "")
        if not prompt:
            raise HTTPException(status_code=400, detail="Prompt required")
        result = run_brain(prompt)
        logger.info("Brain task executed", prompt=prompt[:50])
        return {"result": result}
    except Exception as e:
        logger.error("Brain task failed", error=str(e))
        raise HTTPException(status_code=500, detail=f"Brain task failed: {str(e)}")

@app.post("/api/federated/create", dependencies=[Depends(get_current_user)])
async def create_federated_round(req: FederatedRoundRequest):
    try:
        round_id = await federated_manager.create_federated_round(req.model_architecture, req.participants)
        logger.info(f"Federated round created: {round_id}")
        return {"round_id": round_id}
    except ValueError as ve:
        logger.error(f"Federated round creation failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Federated round creation failed: {e}")
        raise HTTPException(status_code=500, detail="Federated round creation failed")

@app.post("/api/federated/update", dependencies=[Depends(get_current_user)])
async def submit_model_update(req: FederatedUpdateRequest):
    try:
        success = await federated_manager.submit_model_update(req.round_id, config.NODE_ID, req.model_weights)
        logger.info(f"Model update submitted for round {req.round_id}")
        return {"success": success}
    except ValueError as ve:
        logger.error(f"Model update failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Model update failed: {e}")
        raise HTTPException(status_code=500, detail="Model update failed")

@app.post("/api/swarm/create", dependencies=[Depends(get_current_user)])
async def create_swarm(req: SwarmRequest):
    try:
        swarm_id = await swarm_engine.create_swarm(req.problem, req.dimensions, req.agents)
        logger.info(f"Swarm created: {swarm_id}")
        return {"swarm_id": swarm_id}
    except ValueError as ve:
        logger.error(f"Swarm creation failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Swarm creation failed: {e}")
        raise HTTPException(status_code=500, detail="Swarm creation failed")

@app.post("/api/swarm/step", dependencies=[Depends(get_current_user)])
async def step_swarm(req: SwarmStepRequest):
    try:
        result = await swarm_engine.step_swarm(req.swarm_id)
        logger.info(f"Swarm stepped: {req.swarm_id}")
        return result
    except ValueError as ve:
        logger.error(f"Swarm step failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Swarm step failed: {e}")
        raise HTTPException(status_code=500, detail="Swarm step failed")

@app.post("/api/blockchain/submit", dependencies=[Depends(get_current_user)])
async def submit_to_blockchain(req: BlockchainSubmitRequest, background_tasks: BackgroundTasks):
    try:
        tx_hash = await blockchain_manager.submit_data(req.data, background_tasks)
        logger.info(f"Blockchain transaction submitted: {tx_hash}")
        return {"tx_hash": tx_hash}
    except ValueError as ve:
        logger.error(f"Blockchain submission failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Blockchain submission failed: {e}")
        raise HTTPException(status_code=500, detail="Blockchain submission failed")

@app.post("/api/task/create", dependencies=[Depends(get_current_user)])
async def create_task(req: TaskRequest):
    try:
        task_id = str(uuid.uuid4())
        async with asyncpg.create_pool(config.DB_URL) as pool:
            async with pool.acquire() as conn:
                await conn.execute(
                    "INSERT INTO tasks (task_id, task_type, payload, status) VALUES ($1, $2, $3, $4)",
                    task_id, req.task_type, json.dumps(req.payload), "pending"
                )
        process_task.delay(task_id, req.task_type, req.payload)
        logger.info(f"Task created: {task_id}")
        return {"task_id": task_id}
    except ValueError as ve:
        logger.error(f"Task creation failed: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.error(f"Task creation failed: {e}")
        raise HTTPException(status_code=500, detail="Task creation failed")

@app.post("/api/ecommerce/create_account", dependencies=[Depends(get_current_user)])
async def create_ecommerce_account(platform: str, index: int):
    try:
        username, token = await create_platform_account(platform, index)
        logger.info(f"Created account on {platform}", username=username)
        return {"username": username, "token": token}
    except Exception as e:
        logger.error(f"Account creation failed: {e}")
        raise HTTPException(status_code=500, detail=f"Account creation failed: {str(e)}")

@app.post("/api/ecommerce/list_product", dependencies=[Depends(get_current_user)])
async def list_ecommerce_product(product: Product, platform: str):
    try:
        success = await list_product_on_platform(product.dict(), platform)
        logger.info(f"Listed product on {platform}", sku=product.sku)
        return {"success": success}
    except Exception as e:
        logger.error(f"Product listing failed: {e}")
        raise HTTPException(status_code=500, detail=f"Product listing failed: {str(e)}")

@app.post("/api/ecommerce/fulfill_order", dependencies=[Depends(get_current_user)])
async def fulfill_ecommerce_order(req: OrderFulfillRequest):
    try:
        success = await fulfill_order(
            req.order_id, req.platform, req.sku, req.buyer_name, req.buyer_address, req.supplier
        )
        logger.info(f"Fulfilled order {req.order_id}")
        return {"success": success}
    except Exception as e:
        logger.error(f"Order fulfillment failed: {e}")
        raise HTTPException(status_code=500, detail=f"Order fulfillment failed: {str(e)}")

@app.get("/api/nodes", dependencies=[Depends(get_current_user)])
async def get_nodes():
    nodes = []
    async for key in redis_client.scan_iter("node:*"):
        node_data = await redis_client.hgetall(key)
        nodes.append({"id": key.decode().split(":")[1], **{k.decode(): v.decode() for k, v in node_data.items()}})
    return nodes

@app.get("/api/bots/status", dependencies=[Depends(get_current_user)])
async def get_bots_status():
    try:
        async with asyncpg.create_pool(config.DB_URL) as pool:
            async with pool.acquire() as conn:
                bots = await conn.fetch("SELECT bot_name, last_run, status, execution_time, errors FROM bot_runs ORDER BY last_run DESC")
        return {
            "bots": [
                {
                    "name": bot["bot_name"],
                    "last_run": bot["last_run"].isoformat() if bot["last_run"] else "N/A",
                    "status": bot["status"],
                    "execution_time": bot["execution_time"],
                    "errors": bot["errors"]
                }
                for bot in bots
            ]
        }
    except Exception as e:
        logger.error("Failed to fetch bot status", error=str(e))
        raise HTTPException(status_code=500, detail="Internal server error")

@app.post("/api/deploy/{bot_name}", dependencies=[Depends(get_current_user)])
async def deploy_bot(bot_name: str):
    try:
        bot_path = f"bots/{bot_name}.py"
        if not os.path.exists(bot_path):
            logger.error("Bot file not found", bot_path=bot_path)
            raise HTTPException(status_code=404, detail="Bot not found")
        await redis_client.publish(f"nova:deploy:{bot_name}", json.dumps({"path": bot_path}))
        await track_bot_run(bot_name, 0, 0, "Deployed")
        logger.info("Bot deployment triggered", bot=bot_name)
        return {"message": f"Deployed {bot_name}"}
    except Exception as e:
        logger.error("Bot deployment failed", bot=bot_name, error=str(e))
        raise HTTPException(status_code=500, detail=f"Deployment failed: {str(e)}")

@app.post("/api/bots/upload", dependencies=[Depends(get_current_user)])
async def upload_bot(file: UploadFile = File(...)):
    try:
        bot_name = f"bot_{uuid.uuid4().hex[:8]}.py"
        bot_path = os.path.join("bots", bot_name)
        os.makedirs("bots", exist_ok=True)
        with open(bot_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
        await track_bot_run(bot_name, 0, 0, "Uploaded")
        logger.info("Bot uploaded successfully", bot=bot_name)
        return {"message": f"Successfully uploaded {bot_name}"}
    except Exception as e:
        logger.error("Bot upload failed", error=str(e))
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

@app.get("/api/status", dependencies=[Depends(get_current_user)])
async def get_status():
    try:
        cache_key = "system_status"
        cached_status = await redis_client.get(cache_key)
        if cached_status:
            return json.loads(cached_status)
        async with asyncpg.create_pool(config.DB_URL) as pool:
            async with pool.acquire() as conn:
                nodes = await conn.fetch("SELECT node_id, status, last_seen FROM nodes")
                vaults = await conn.fetch("SELECT label, created_at FROM vaults")
                tasks = await conn.fetch("SELECT task_id, status FROM tasks LIMIT 10")
                txns = await conn.fetch("SELECT tx_hash, status FROM blockchain_txns LIMIT 10")
                rounds = await conn.fetch("SELECT round_id, status FROM federated_rounds LIMIT 10")
                swarms = await conn.fetch("SELECT swarm_id, status FROM swarm_intelligence LIMIT 10")
                accounts = await